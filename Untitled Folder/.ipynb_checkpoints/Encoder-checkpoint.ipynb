{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoder_layer(self):\n",
    "    initial_state = (tf.zeros([batch_size, rnn_hidden]), tf.zeros([batch_size, rnn_hidden]))\n",
    "    state = initial_state\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(hidden_size)\n",
    "    outputs = []\n",
    "    states = []\n",
    "    \n",
    "    for i in xrange(num_steps):\n",
    "        output, state = cell(inputs, state)\n",
    "        inputs = output\n",
    "        outputs.append(output)\n",
    "        states.append(state)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "input_size = 8\n",
    "time_step_size = 4\n",
    "rnn_hidden = 4\n",
    "num_encoder_symbols = 10\n",
    "#x_data = tf.zeros([batch_size, input_size])\n",
    "#X_split = tf.split(x_data, time_step_size, 1) \n",
    "initial_state = (tf.zeros([batch_size, rnn_hidden]), tf.zeros([batch_size, rnn_hidden]))\n",
    "\n",
    "input_placeholder = tf.placeholder(tf.int32, [batch_size, input_size])\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(rnn_hidden)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_vocab_size = 10\n",
    "initializer = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "embedded = embedding(input_placeholder, source_vocab_size, rnn_hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#embedded_reshape = tf.reshape(embedded[1], [batch_size, rnn_hidden])\n",
    "print (embedded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "          embedding = tf.get_variable(\"embedding\", [self._embedding_classes,\n",
    "                                                    self._cell.input_size],\n",
    "                                      initializer=initializer)\n",
    "        embedded = tf.nn.embedding_lookup(embedding, tf.reshape(inputs, [-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output, new_state = cell(embedded[1], initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn_outputs, rnn_states = tf.contrib.rnn.static_rnn(cell, X_split, initial_state=initial_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def embedding(inputs, source_vocab_size, rnn_hidden):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    cell: output from basicLSTMcell\n",
    "    num_encoder_symbols: source vocabulary size\n",
    "    embed_size\n",
    "    initializer\n",
    "\n",
    "    output:\n",
    "    a tuple of embedded input and state of the cell\n",
    "    \"\"\"\n",
    "    with tf.device('/cpu:0'):\n",
    "      ### YOUR CODE HERE\n",
    "      with tf.variable_scope(\"embedding\") as scope:\n",
    "            L = tf.get_variable(\"L\",[source_vocab_size, rnn_hidden], initializer = initializer)\n",
    "            embeds = tf.nn.embedding_lookup(L, input_placeholder)\n",
    "            inputs = [tf.squeeze(x) for x in tf.split(embeds, [tf.ones([time_step_size], tf.int32)], 1)]\n",
    "\n",
    "      ### END YOUR CODE\n",
    "      return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    print(rnn_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Config(object):\n",
    "    \n",
    "    source_vocab_size\n",
    "    target_vocab_size\n",
    "    buckets\n",
    "    batch_size\n",
    "    rnn_size\n",
    "    learning_rate = tf.Variable(\n",
    "        float(learning_rate), trainable=False, dtype=dtype)\n",
    "    learning_rate_decay_op = self.learning_rate.assign(\n",
    "        self.learning_rate * learning_rate_decay_factor)\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    embed_size\n",
    "    initializer\n",
    "\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "\n",
    "#1. Encoder\n",
    "class encoder(language model):\n",
    "\n",
    "    ##1.1 Embedding\n",
    "    def embedding(self):\n",
    "        \"\"\"\n",
    "        input:\n",
    "        cell: output from basicLSTMcell\n",
    "        num_encoder_symbols: source vocabulary size\n",
    "        embed_size\n",
    "        initializer\n",
    "\n",
    "        output:\n",
    "        a tuple of embedded input and state of the cell\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\"Embedding\"): \n",
    "            embedding = tf.get_variable(\"embedding\", [self.config.source_vocab_size, self.config.embed_size], \n",
    "                                        initializer=self.config.initializer)\n",
    "            inputs = cell[0]\n",
    "            state = cell[1]\n",
    "            embedded = tf.nn.embedding_lookup(embedding, tf.reshape(inputs, [-1]))\n",
    "        return (embedded, state)\n",
    "\n",
    "    ##1.2 Encoder RNN\n",
    "    def rnn(cell, inputs, initial_state=None, dtype=None, sequence_length=None, scope=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        cell: An instance of RNNCell.\n",
    "        inputs: Encoder inputs, with shape [batch_size, encoder_size].\n",
    "        initial_state: (optional) An initial state for the RNN.  This must be\n",
    "          a tensor of appropriate type and shape [batch_size x cell.state_size].\n",
    "        dtype: (optional) The data type for the initial state.  Required if\n",
    "          initial_state is not provided.\n",
    "        sequence_length: An int64 vector (tensor) size [batch_size].\n",
    "        scope: VariableScope for the created subgraph; defaults to \"RNN\".\n",
    "        Returns:\n",
    "        A pair (outputs, states) where:\n",
    "          outputs is a length T list of outputs (one for each input)\n",
    "          states is a length T list of states (one state following each input)\n",
    "        \"\"\"\n",
    "        outputs = []\n",
    "        states = []\n",
    "        with tf.variable_scope(scope or \"RNN\"):\n",
    "            batch_size = tf.shape(inputs[0])[0]\n",
    "            if initial_state is not None:\n",
    "                state = initial_state\n",
    "            else:\n",
    "                if not dtype:\n",
    "                    raise ValueError(\"If no initial_state is provided, dtype must be.\")\n",
    "                state = cell.zero_state(batch_size, dtype)\n",
    "\n",
    "            if sequence_length:  # Prepare variables\n",
    "                zero_output_state = (\n",
    "                  tf.zeros(tf.pack([self.config.batch_size, self.config.decoder_size]),\n",
    "                           inputs[0].dtype),\n",
    "                  tf.zeros(tf.pack([self.config.batch_size, self.config.state_size]),\n",
    "                           state.dtype))\n",
    "                max_sequence_length = tf.reduce_max(sequence_length)\n",
    "\n",
    "            output_state = (None, None)\n",
    "\n",
    "            for time, input_ in enumerate(inputs):\n",
    "                if time > 0:\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "                output_state = cell\n",
    "                if sequence_length:\n",
    "                    (output, state) = control_flow_ops.cond(\n",
    "                        time >= max_sequence_length,\n",
    "                        lambda: zero_output_state, lambda: output_state)\n",
    "                else:\n",
    "                    (output, state) = output_state\n",
    "                    outputs.append(output)\n",
    "                    states.append(state)\n",
    "            return (outputs, states)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
